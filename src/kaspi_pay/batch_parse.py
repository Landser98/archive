#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Batch-–ø–∞—Ä—Å–µ—Ä –¥–ª—è Kaspi Pay / Kaspi Gold –≤—ã–ø–∏—Å–æ–∫.

–¢–µ–ø–µ—Ä—å —É–º–µ–µ—Ç:
  1) –†–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ –ø–æ JSONL (*_pages.jsonl), —Ç–∞–∫ –∏ –Ω–∞–ø—Ä—è–º—É—é –ø–æ PDF:
     - –ø—Ä–∏ PDF —Å–∞–º –≤—ã–∑—ã–≤–∞–µ—Ç dump_pdf_pages() –∏–∑ convert_pdf_json_pages.py,
       —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å JSONL.
  2) –°–æ–∑–¥–∞–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π meta-JSON –ø–æ PDF (creator / creation / mod –∏ —Ç.–ø.),
     –µ—Å–ª–∏ –æ–Ω –µ—â—ë –Ω–µ —Å–æ–∑–¥–∞–Ω.
  3) –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∫ –æ–¥–∏–Ω —Ñ–∞–π–ª, —Ç–∞–∫ –∏ –ø–∞–ø–∫—É.
  4) –ü–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞:
       - –¥–µ–ª–∞–µ—Ç —á–∏—Å–ª–æ–≤—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –±–∞–ª–∞–Ω—Å–∞ (opening + Œ£–ö—Ä–µ–¥–∏—Ç ‚àí Œ£–î–µ–±–µ—Ç = closing);
       - –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç PDF-–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (CreationDate / ModDate / Creator / Producer),
         –∏—Å–ø–æ–ª—å–∑—É—è utils.statement_validation.validate_pdf_metadata_from_json().

–ù–∞ –≤—Ö–æ–¥:
  - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (PDF –∏–ª–∏ *_pages.jsonl) –ò–õ–ò –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.

–ù–∞ –≤—ã—Ö–æ–¥ –ø–æ –∫–∞–∂–¥–æ–º—É —Å—Ç–µ–π—Ç–º–µ–Ω—Ç—É (stem = –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞):
  <stem>_header.csv
  <stem>_tx.csv
  <stem>_footer.csv             (–µ—Å–ª–∏ —Ñ—É—Ç–µ—Ä –µ—Å—Ç—å)
  <stem>_tx_ip.csv
  <stem>_ip_income_monthly.csv
  (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) meta JSON:
  <stem>_pdf_meta.json          (–≤ –ø–∞–ø–∫–µ --pdf-meta-dir)
"""

import argparse
import sys
import json
from pathlib import Path
from typing import Sequence, Dict, Any, Tuple, List, Optional

import pandas as pd
from src.config import DATA_DIR

from src.kaspi_pay.parser import parse_kaspi_pay_statement
from src.utils.income_calc import compute_ip_income
from src.utils.convert_pdf_json_pages import dump_pdf_pages
from src.utils.statement_validation import validate_pdf_metadata_from_json
from src.kaspi_pay.header import _normalize_amount_to_float
from src.utils.statement_validation import BANK_SCHEMAS, validate_statement_generic, validate_pdf_metadata_from_json



# ---------------------------------------------------------------------
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ---------------------------------------------------------------------
def _pick_first_existing(cols: Sequence[str], candidates, fallback=None):
    """–í–µ—Ä–Ω—É—Ç—å –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü –∏–∑ candidates, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å –≤ DataFrame."""
    for c in candidates:
        if c in cols:
            return c
    return fallback


def _parse_number_ru(val: Any) -> float:
    """'5 576 876,37' / '0,00' / 5.0 / None ‚Üí float (–¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏)."""
    if val is None:
        return 0.0
    if isinstance(val, (int, float)):
        try:
            return float(val)
        except (TypeError, ValueError):
            return 0.0

    s = str(val)
    s = s.replace("\xa0", " ").replace("\u202f", " ")
    s = s.replace(" ", "").replace(",", ".")
    if not s:
        return 0.0
    try:
        return float(s)
    except ValueError:
        return 0.0


def _ensure_jsonl_for_pdf(pdf_path: Path, jsonl_dir: Path) -> Path:
    """–î–ª—è –¥–∞–Ω–Ω–æ–≥–æ PDF –≤–µ—Ä–Ω—É—Ç—å –ø—É—Ç—å –∫ *_pages.jsonl, –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ ‚Äì —Å–æ–∑–¥–∞—Ç—å."""
    jsonl_dir.mkdir(parents=True, exist_ok=True)
    jsonl_path = jsonl_dir / f"{pdf_path.stem}_pages.jsonl"
    if jsonl_path.exists():
        return jsonl_path

    print(f"   ‚ñ∂ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º JSONL —á–µ—Ä–µ–∑ dump_pdf_pages() ‚Üí {jsonl_path}")
    # dump_pdf_pages —Å–∞–º –ø—Ä–∏–¥—É–º–∞–µ—Ç –∏–º—è, –µ—Å–ª–∏ out_path=None; –Ω–æ –∑–¥–µ—Å—å –º—ã —è–≤–Ω–æ –∑–∞–¥–∞—ë–º.
    written = dump_pdf_pages(pdf_path=pdf_path, out_path=jsonl_path)
    # written –º–æ–∂–µ—Ç –±—ã—Ç—å –ª–∏–±–æ Path, –ª–∏–±–æ —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π ‚Äì –∑–∞—â–∏—â–∞–µ–º—Å—è:
    if isinstance(written, (list, tuple)):
        # –∏—â–µ–º –ø–µ—Ä–≤—ã–π *_pages.jsonl —Å—Ä–µ–¥–∏ –≤–æ–∑–≤—Ä–∞—â—ë–Ω–Ω—ã—Ö
        for p in written:
            p = Path(p)
            if p.name.endswith("_pages.jsonl") and p.exists():
                return p
    elif isinstance(written, (str, Path)):
        p = Path(written)
        if p.exists():
            return p

    # Fallback: –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–∏–º –Ω–∞—à–µ–º—É target-–ø—É—Ç–∏
    return jsonl_path


def _extract_pdf_meta_from_jsonl(jsonl_path: Path) -> Dict[str, Any]:
    """
    –î–æ—Å—Ç–∞—ë–º pdf.metadata.

    1) –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏ JSONL (–µ—Å–ª–∏ dump_pdf_pages —Ç—É–¥–∞ –ø–∏—à–µ—Ç).
    2) –ï—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äì –ø—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –∏–∑ –±–æ–ª—å—à–æ–≥–æ –∫–∞—Ç–∞–ª–æ–∂–Ω–æ–≥–æ JSON
       DATA_DIR/converted_jsons/<pdf_stem>.json,
       –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç convert_pdf_json_page.py.
    """
    meta: Dict[str, Any] = {}

    # --- 1. –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–∑ JSONL ---
    try:
        with open(jsonl_path, "r", encoding="utf-8") as f:
            first_line = f.readline().strip()
        if first_line:
            first_page = json.loads(first_line)
            meta = first_page.get("metadata") or {}
    except Exception as e:
        print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É JSONL –¥–ª—è meta: {e}")

    if meta:
        # —É–∂–µ –µ—Å—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è –º–µ—Ç–∞ –≤–Ω—É—Ç—Ä–∏ JSONL
        return {"metadata": meta}

    # --- 2. –§–æ–ª–±—ç–∫: –±–æ–ª—å—à–æ–π JSON –æ—Ç convert_pdf_json_page.py ---
    try:
        pdf_stem = jsonl_path.stem
        # –Ω–∞—à–∏ jsonl –æ–±—ã—á–Ω–æ <stem>_pages.jsonl ‚Üí –æ—Ç—Ä–µ–∂–µ–º —Ö–≤–æ—Å—Ç "_pages"
        if pdf_stem.endswith("_pages"):
            pdf_stem = pdf_stem[:-6]

        catalog_json = Path(DATA_DIR) / "converted_jsons" / f"{pdf_stem}.json"
        if catalog_json.exists():
            with open(catalog_json, "r", encoding="utf-8") as f:
                big = json.load(f)
            fallback_meta = big.get("metadata") or {}
            if fallback_meta:
                print(f"   ‚ìò metadata –≤–∑—è–ª–∏ –∏–∑ {catalog_json.name}")
                return {"metadata": fallback_meta}
    except Exception as e:
        print(f"   ‚ö†Ô∏è –§–æ–ª–±—ç–∫ —á—Ç–µ–Ω–∏—è meta –∏–∑ –∫–∞—Ç–∞–ª–æ–∂–Ω–æ–≥–æ JSON –Ω–µ —É–¥–∞–ª—Å—è: {e}")

    # –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏
    return {}


def _save_meta_if_missing(meta_json: Dict[str, Any], meta_path: Path) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å meta_json –≤ meta_path.

    –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –µ—Å—Ç—å –∏ –≤ –Ω—ë–º –µ—Å—Ç—å –Ω–µ–ø—É—Å—Ç–æ–π metadata ‚Äì –Ω–µ —Ç—Ä–æ–≥–∞–µ–º.
    –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç –ò–õ–ò –≤ –Ω—ë–º metadata –ø—É—Å—Ç–æ–π, –∞ –Ω–æ–≤—ã–π meta_json —Å–æ–¥–µ—Ä–∂–∏—Ç —á—Ç–æ-—Ç–æ ‚Äì
    –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º.
    """
    meta_path.parent.mkdir(parents=True, exist_ok=True)

    # –µ—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –µ—Å—Ç—å ‚Äì –ø–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ –≤ –Ω—ë–º
    if meta_path.exists():
        try:
            with open(meta_path, "r", encoding="utf-8") as f:
                existing = json.load(f)
            existing_meta = existing.get("metadata") or {}
            new_meta = meta_json.get("metadata") or {}

            # –µ—Å–ª–∏ —Å—Ç–∞—Ä—ã–π —É–∂–µ —Å –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π –º–µ—Ç–æ–π –∏–ª–∏ –Ω–æ–≤–∞—è —Ç–æ–∂–µ –ø—É—Å—Ç–∞—è ‚Äì –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
            if existing_meta and not new_meta:
                return
            if existing_meta and new_meta:
                return
        except Exception:
            # –µ—Å–ª–∏ —Ñ–∞–π–ª –±–∏—Ç—ã–π ‚Äì –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ–º –Ω–∏–∂–µ
            pass

    # —Å—é–¥–∞ –ø–æ–ø–∞–¥–∞–µ–º, –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç –∏–ª–∏ –º–µ—Ç–∞ –±—ã–ª–∞ –ø—É—Å—Ç–∞—è
    try:
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(meta_json, f, ensure_ascii=False, indent=2)
        print(f"   ‚úÖ Meta JSON   ‚Üí {meta_path}")
    except Exception as e:
        print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å meta JSON {meta_path}: {e}")

def _run_numeric_validation_kaspi(
    header_df: pd.DataFrame,
    tx_df: pd.DataFrame,
    footer_df: Optional[pd.DataFrame],
    tol: float = 0.01,
) -> Tuple[List[str], Dict[str, Any]]:
    """–ü—Ä–æ—Å—Ç–∞—è —á–∏—Å–ª–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è Kaspi Pay / Gold.

    –ü—Ä–æ–≤–µ—Ä—è–µ–º:
      - opening + Œ£–ö—Ä–µ–¥–∏—Ç ‚àí Œ£–î–µ–±–µ—Ç ‚âà closing
      - (–µ—Å–ª–∏ –µ—Å—Ç—å —Ñ—É—Ç–µ—Ä) total_credit_turnover / total_debit_turnover vs Œ£ –ø–æ tx
    """
    flags: List[str] = []
    debug: Dict[str, Any] = {}

    if header_df.empty or tx_df.empty:
        flags.append("empty_header_or_tx")
        return flags, debug

    row = header_df.iloc[0]

    opening_raw = row.get("–í—Ö–æ–¥—è—â–∏–π –æ—Å—Ç–∞—Ç–æ–∫")
    closing_raw = row.get("–ò—Å—Ö–æ–¥—è—â–∏–π –æ—Å—Ç–∞—Ç–æ–∫")

    opening_val, opening_ccy = _normalize_amount_to_float(opening_raw) if isinstance(opening_raw, str) else (None, None)
    closing_val, closing_ccy = _normalize_amount_to_float(closing_raw) if isinstance(closing_raw, str) else (None, None)

    debug.update(
        opening_raw=opening_raw,
        closing_raw=closing_raw,
        opening_val=opening_val,
        closing_val=closing_val,
        opening_ccy=opening_ccy,
        closing_ccy=closing_ccy,
    )

    if opening_val is None or closing_val is None:
        flags.append("cannot_parse_opening_or_closing_balance")
        return flags, debug

    total_credit = pd.to_numeric(tx_df.get("–ö—Ä–µ–¥–∏—Ç"), errors="coerce").fillna(0.0).sum()
    total_debit = pd.to_numeric(tx_df.get("–î–µ–±–µ—Ç"), errors="coerce").fillna(0.0).sum()

    closing_calc = opening_val + total_credit - total_debit

    debug.update(
        total_credit=total_credit,
        total_debit=total_debit,
        closing_calc=closing_calc,
        tolerance=tol,
    )

    if abs(closing_calc - closing_val) > tol:
        flags.append("closing_balance_mismatch")

    # --- —Ñ—É—Ç–µ—Ä: total_debit_turnover / total_credit_turnover ---
    if footer_df is not None and not footer_df.empty:
        fr = footer_df.iloc[0]
        credit_footer = fr.get("total_credit_turnover")
        debit_footer = fr.get("total_debit_turnover")

        credit_footer_val = _parse_number_ru(credit_footer) if credit_footer is not None else None
        debit_footer_val = _parse_number_ru(debit_footer) if debit_footer is not None else None

        debug.update(
            footer_total_credit_turnover=credit_footer_val,
            footer_total_debit_turnover=debit_footer_val,
        )

        if credit_footer_val is not None and abs(credit_footer_val - total_credit) > tol:
            flags.append("footer_credit_turnover_mismatch")
        if debit_footer_val is not None and abs(debit_footer_val - total_debit) > tol:
            flags.append("footer_debit_turnover_mismatch")

    return flags, debug


def _process_one(
    jsonl_path: Path,
    out_dir: Path,
    pdf_meta_dir: Optional[Path] = None,
) -> None:
    print(f"{jsonl_path.name}")

    # --- PDF meta –∏–∑ JSONL ---
    pdf_meta_json: Optional[Dict[str, Any]] = None
    meta_path: Optional[Path] = None
    if pdf_meta_dir is not None:
        pdf_meta_json = _extract_pdf_meta_from_jsonl(jsonl_path)
        if pdf_meta_json:
            meta_path = pdf_meta_dir / f"{jsonl_path.stem}_pdf_meta.json"
            _save_meta_if_missing(pdf_meta_json, meta_path)

    # --- –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç–µ–π—Ç–º–µ–Ω—Ç–∞ ---
    header_df, tx_df, footer_df = parse_kaspi_pay_statement(str(jsonl_path))

    stem = jsonl_path.stem
    out_header         = out_dir / f"{stem}_header.csv"
    out_tx             = out_dir / f"{stem}_tx.csv"
    out_footer         = out_dir / f"{stem}_footer.csv"
    out_tx_ip          = out_dir / f"{stem}_tx_ip.csv"
    out_ip_monthly     = out_dir / f"{stem}_ip_income_monthly.csv"
    out_income_summary = out_dir / f"{stem}_income_summary.csv"

    # --- –±–∞–∑–æ–≤—ã–µ CSV ---
    header_df.to_csv(out_header, index=False, encoding="utf-8-sig")
    tx_df.to_csv(out_tx, index=False, encoding="utf-8-sig")

    # --- –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º footer ---
    if footer_df is None:
        df_footer = None
    elif isinstance(footer_df, pd.DataFrame):
        df_footer = footer_df
    elif isinstance(footer_df, list):
        df_footer = pd.DataFrame(footer_df)
    elif isinstance(footer_df, dict):
        df_footer = pd.DataFrame([footer_df])
    else:
        df_footer = pd.DataFrame()

    if df_footer is not None and not df_footer.empty:
        df_footer.to_csv(out_footer, index=False, encoding="utf-8-sig")
        print(f"   ‚úÖ Footer      ‚Üí {out_footer}")
    else:
        print("   ‚ö†Ô∏è Footer      ‚Üí –ø—É—Å—Ç–æ–π (–Ω–µ –∑–∞–ø–∏—Å–∞–Ω)")

    # === —Ä–∞—Å—á—ë—Ç –¥–æ—Ö–æ–¥–∞ –ò–ü –ø–æ Kaspi Pay ===
    cols = list(tx_df.columns)

    col_op_date = _pick_first_existing(cols, ["–î–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏", "–î–∞—Ç–∞"], fallback=cols[1])
    col_credit = _pick_first_existing(cols, ["–ö—Ä–µ–¥–∏—Ç"], fallback=cols[3])
    col_knp = _pick_first_existing(cols, ["–ö–ù–ü"], fallback=None)
    col_purpose = _pick_first_existing(cols, ["–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –ø–ª–∞—Ç–µ–∂–∞"], fallback=cols[-1])
    col_counterparty = _pick_first_existing(
        cols,
        [
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–∞—Ç–µ–ª—è",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–∞—Ç–µ–ª—è (–±–µ–Ω–µ—Ñ)",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–∞—Ç–µ–ª—è (–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –¥–µ–Ω–µ–≥)",
        ],
        fallback=cols[4] if len(cols) > 4 else cols[-1],
    )

    if col_knp is None:
        tx_df["–ö–ù–ü"] = ""
        col_knp = "–ö–ù–ü"

    # üîÅ —Ç–µ–ø–µ—Ä—å compute_ip_income –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç income_summary (dict)
    enriched_tx, monthly_income, income_summary = compute_ip_income(
        tx_df,
        col_op_date=col_op_date,
        col_credit=col_credit,
        col_knp=col_knp,
        col_purpose=col_purpose,
        col_counterparty=col_counterparty,
        months_back=12,
        op_date_pattern=r"(\d{2}\.\d{2}\.\d{4})",  # dd.mm.yyyy
        op_date_format="%d.%m.%Y",
        verbose=True,
        max_examples=5,
    )

    # dict ‚Üí DataFrame –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    income_summary_df = pd.DataFrame([income_summary])

    enriched_tx.to_csv(out_tx_ip, index=False, encoding="utf-8-sig")
    monthly_income.to_csv(out_ip_monthly, index=False, encoding="utf-8-sig")
    income_summary_df.to_csv(out_income_summary, index=False, encoding="utf-8-sig")

    print(f"   ‚úÖ Header      ‚Üí {out_header}")
    print(f"   ‚úÖ Tx          ‚Üí {out_tx}")
    if df_footer is not None and not df_footer.empty:
        print(f"   ‚úÖ Tx+IP       ‚Üí {out_tx_ip}")
    else:
        print(f"   ‚úÖ Tx+IP       ‚Üí {out_tx_ip}")
    print(f"   ‚úÖ IP monthly  ‚Üí {out_ip_monthly}")
    print(f"   ‚úÖ Income summary ‚Üí {out_income_summary}")

    adj = income_summary.get("total_income_adjusted")
    if adj is not None:
        print(f"   ‚úÖ Adjusted income: {adj:,.2f}")
    else:
        print("   ‚úÖ Adjusted income: N/A")

    # === –ß–ò–°–õ–û–í–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø ===
    num_flags, num_debug = _run_numeric_validation_kaspi(header_df, tx_df, df_footer)
    if num_flags:
        print(f"   ‚ö†Ô∏è Numeric validation flags: {num_flags}")
    else:
        print("   ‚úÖ Numeric validation: OK")

    # === PDF META –í–ê–õ–ò–î–ê–¶–ò–Ø ===
    if pdf_meta_json:
        period_start = str(header_df.iloc[0].get("–ü–µ—Ä–∏–æ–¥ (–Ω–∞—á–∞–ª–æ)") or "")
        period_end = str(header_df.iloc[0].get("–ü–µ—Ä–∏–æ–¥ (–∫–æ–Ω–µ—Ü)") or "")

        pdf_flags, pdf_debug = validate_pdf_metadata_from_json(
            pdf_meta_json,
            bank="KASPI_PAY",
            period_start=period_start or None,
            period_end=period_end or None,
            period_date_format="%d.%m.%Y",
            max_days_after_period_end=7,
            allowed_creators=None,
            allowed_producers=None,
        )

        if pdf_flags:
            print(f"   ‚ö†Ô∏è PDF metadata flags: {pdf_flags}")
        else:
            print("   ‚úÖ PDF metadata: OK")

        print(
            "   ‚ìò PDF meta: Creator={creator}, Producer={producer}, Creation={creation}, Mod={mod}".format(
                creator=pdf_debug.get("pdf_creator"),
                producer=pdf_debug.get("pdf_producer"),
                creation=pdf_debug.get("pdf_creation_dt"),
                mod=pdf_debug.get("pdf_mod_dt"),
            )
        )
    else:
        print("   ‚ö†Ô∏è PDF meta: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ JSONL (metadata –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)")


def main() -> None:
    ap = argparse.ArgumentParser(
        description="Batch: Kaspi Pay / Kaspi Gold ‚Üí header/tx/footer + IP income + validation"
    )
    ap.add_argument(
        "root",
        help="–§–∞–π–ª (PDF –∏–ª–∏ *_pages.jsonl) –ò–õ–ò –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ç–∞–∫–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏",
    )
    ap.add_argument(
        "--pattern",
        default="*_pages.jsonl",
        help="–ì–ª–æ–±-–ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤. –î–ª—è JSONL –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é '*_pages.jsonl', –¥–ª—è PDF ‚Äì '*.pdf'.",
    )
    ap.add_argument(
        "--out-dir",
        required=True,
        help="–ö—É–¥–∞ –ø–∏—Å–∞—Ç—å CSV (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)",
    )
    ap.add_argument(
        "--max-files",
        type=int,
        default=None,
        help="–ú–∞–∫—Å–∏–º—É–º —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–¥–ª—è —Ç–µ—Å—Ç–∞)",
    )
    ap.add_argument(
        "--input-type",
        choices=["jsonl", "pdf"],
        default="jsonl",
        help="–¢–∏–ø –≤—Ö–æ–¥–∞: jsonl (—Å—Ç–∞—Ä–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ) –∏–ª–∏ pdf (–∞–≤—Ç–æ-—Å–æ–∑–¥–∞–Ω–∏–µ JSONL)",
    )
    ap.add_argument(
        "--jsonl-dir",
        default=None,
        help="–ö—É–¥–∞ —Å–∫–ª–∞–¥—ã–≤–∞—Ç—å/–≥–¥–µ –∏—Å–∫–∞—Ç—å *_pages.jsonl –ø—Ä–∏ input-type=pdf. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: <out-dir>/converted_jsons",
    )
    ap.add_argument(
        "--pdf-meta-dir",
        default=None,
        help="–ö—É–¥–∞ –ø–∏—Å–∞—Ç—å pdf_meta.json. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: <out-dir>/pdf_meta",
    )

    args = ap.parse_args()

    root = Path(args.root)
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    # --- –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è PDF-—Ä–µ–∂–∏–º–∞ ---
    jsonl_dir = None
    pdf_meta_dir = None
    if args.input_type == "pdf":
        jsonl_dir = Path(args.jsonl_dir) if args.jsonl_dir else (out_dir / "converted_jsons")
        jsonl_dir.mkdir(parents=True, exist_ok=True)
        pdf_meta_dir = Path(args.pdf_meta_dir) if args.pdf_meta_dir else (out_dir / "pdf_meta")
        pdf_meta_dir.mkdir(parents=True, exist_ok=True)
    else:
        # jsonl-—Ä–µ–∂–∏–º: pdf_meta_dir –º–æ–∂–µ–º —Ç–æ–∂–µ —Å–æ–∑–¥–∞—Ç—å, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if args.pdf_meta_dir:
            pdf_meta_dir = Path(args.pdf_meta_dir)
            pdf_meta_dir.mkdir(parents=True, exist_ok=True)

    # --- —Ä–µ–∂–∏–º: –µ–¥–∏–Ω–∏—á–Ω—ã–π —Ñ–∞–π–ª ---
    if root.is_file():
        if args.input_type == "jsonl":
            jsonl_path = root
            _process_one(jsonl_path, out_dir, pdf_meta_dir)
        else:  # pdf
            if root.suffix.lower() != ".pdf":
                raise SystemExit(f"–û–∂–∏–¥–∞–µ—Ç—Å—è PDF, –∞ –ø–æ–ª—É—á–µ–Ω–æ: {root}")
            assert jsonl_dir is not None
            jsonl_path = _ensure_jsonl_for_pdf(root, jsonl_dir)
            _process_one(jsonl_path, out_dir, pdf_meta_dir)
        return

    # --- —Ä–µ–∂–∏–º: –ø–∞–ø–∫–∞ ---
    if not root.is_dir():
        raise SystemExit(f"Root is neither file nor directory: {root}")

    if args.input_type == "jsonl":
        in_paths = sorted(root.rglob(args.pattern))
        if not in_paths:
            print(f"‚ö†Ô∏è JSONL –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {root} (pattern={args.pattern})")
            return
    else:
        # PDF-—Ä–µ–∂–∏–º
        pattern = args.pattern if args.pattern != "*_pages.jsonl" else "*.pdf"
        in_paths = sorted(root.rglob(pattern))
        if not in_paths:
            print(f"‚ö†Ô∏è PDF –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {root} (pattern={pattern})")
            return

    if args.max_files is not None:
        in_paths = in_paths[: args.max_files]

    print(f"–ù–∞—à—ë–ª {len(in_paths)} —Ñ–∞–π–ª(–æ–≤) –ø–æ–¥ {root}")
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç –ø–∏—Å–∞—Ç—å—Å—è –≤: {out_dir}")

    for i, path in enumerate(in_paths, start=1):
        print(f"\n[{i}/{len(in_paths)}] {path}")
        try:
            if args.input_type == "jsonl":
                jsonl_path = path
            else:
                assert jsonl_dir is not None
                jsonl_path = _ensure_jsonl_for_pdf(path, jsonl_dir)
            _process_one(jsonl_path, out_dir, pdf_meta_dir)
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –Ω–∞ {path}: {e}", file=sys.stderr)


if __name__ == "__main__":
    main()
